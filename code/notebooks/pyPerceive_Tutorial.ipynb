{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for using pyPerceive to select and load Percept recordings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Instructions for using PyPerceive as a toolbox in your own Repo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Requirements and Installations: \n",
    "    - GitHub Account\n",
    "    - Anaconda\n",
    "    - GitHub Desktop\n",
    "    - VS Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create your own GitHub Repository\n",
    "    - In your GitHub Repository go to 'Your repositories' and click on the 'New' button\n",
    "    - Define a repository name, choose 'public', add a README and add .gitignore, choose a licence (e.g. MIT Licence) and create your own repository\n",
    "    - Select a path where to save your repository"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clone the pyPerceive repository using GitHub Desktop\n",
    "    - Go to pyPerceive on GitHub: https://github.com/jgvhabets/PyPerceive\n",
    "    - Click on the green 'Code' button and click on Open with GitHub Desktop\n",
    "    - Choose a local path for cloning the repository"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Open Terminal > New Terminal in VS Code and open your repository by typing: \n",
    "    - github path-to-your-own-repository\n",
    "    - now you are working in your repository"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create your own environment by following the instructions in the README\n",
    "    - after creating your environment, make sure you are working in the correct kernel (upper right corner of VS Code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Load the packages and functions in this notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "from dataclasses import dataclass, field, fields\n",
    "from itertools import compress\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import xlrd\n",
    "\n",
    "#mne\n",
    "import mne_bids\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet \n",
    "\n",
    "\n",
    "\n",
    "from importlib import reload          "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check package versions\n",
    "\n",
    "developed with:\n",
    "- Python sys 3.10.8\n",
    "- pandas 1.5.1\n",
    "- numpy 1.23.4\n",
    "- mne_bids 0.11.1\n",
    "- mne 1.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python sys 3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 1.4.4\n",
      "numpy 1.23.3\n",
      "mne_bids 0.11.1\n",
      "mne 1.2.3\n"
     ]
    }
   ],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "print('mne_bids', mne_bids.__version__)\n",
    "print('mne', mne.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Set the working directory to the pyPerceive repository located on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jebe12\\\\Research\\\\PyPerceive_Project\\\\Code\\\\PyPerceive\\\\code'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is your current working directory \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################     USE THIS DIRECTORY FOR IMPORTING PYPERCEIVE REPO  #######################\n",
    "\n",
    "# get the path to the code folder within your own Repo\n",
    "ownRepository_path = os.getcwd()\n",
    "\n",
    "# get the path from your ownRepository_path from where you could direct to the cloned pyPerceive Repo on your computer, e.g. your path to 'Users' \n",
    "while ownRepository_path[-5:] != 'Users':\n",
    "    ownRepository_path = os.path.dirname(ownRepository_path)\n",
    "\n",
    "# directory to PyPerceive code folder, add the correct folderstructure\n",
    "PyPerceive_path = os.path.join(ownRepository_path, 'PyPerceive', 'code')\n",
    "sys.path.append(PyPerceive_path)\n",
    "\n",
    "# change directory to PyPerceive code path \n",
    "os.chdir(PyPerceive_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Load pyPerceive functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PerceiveImport.classes import (\n",
    "    main_class, modality_class, metadata_class,\n",
    "    session_class, condition_class, task_class,\n",
    "    contact_class, run_class\n",
    ")\n",
    "import PerceiveImport.methods.load_rawfile as load_rawfile\n",
    "import PerceiveImport.methods.find_folders as find_folders\n",
    "import PerceiveImport.methods.metadata_helpers as metaHelpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PerceiveImport.methods.metadata_helpers' from 'c:\\\\Users\\\\jebe12\\\\Research\\\\PyPerceive_Project\\\\Code\\\\PyPerceive\\\\code\\\\PerceiveImport\\\\methods\\\\metadata_helpers.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload classes during debugging\n",
    "importlib.reload(main_class)\n",
    "importlib.reload(session_class)\n",
    "importlib.reload(task_class)\n",
    "importlib.reload(condition_class)\n",
    "importlib.reload(contact_class)\n",
    "importlib.reload(metadata_class)\n",
    "importlib.reload(modality_class)\n",
    "importlib.reload(load_rawfile)\n",
    "importlib.reload(find_folders)\n",
    "importlib.reload(run_class)\n",
    "importlib.reload(metaHelpers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you are already working in the local pyPerceive repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_set_code_folder_in_notebook():\n",
    "    \"\"\"\n",
    "    while working in the local pyPerceive repo,\n",
    "    find and set path to the PyPerceive code folder\n",
    "\n",
    "    use function in notebook first, to locate the local\n",
    "    repo and enable import of pyPerceive functions\n",
    "    \"\"\"\n",
    "    project_path = os.getcwd()\n",
    "\n",
    "    while project_path[-10:] != 'PyPerceive':\n",
    "        project_path = os.path.dirname(project_path)\n",
    "\n",
    "    code_path = os.path.join(project_path, 'code')\n",
    "    sys.path.append(code_path)\n",
    "\n",
    "    # change directory to code path\n",
    "    os.chdir(code_path)\n",
    "    \n",
    "    return print(f'working dir set to: {code_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dir set to: c:\\Users\\jebe12\\Research\\PyPerceive_Project\\Code\\PyPerceive\\code\n"
     ]
    }
   ],
   "source": [
    "# change working directory to ensure correct loading of own functions\n",
    "add_and_set_code_folder_in_notebook()\n",
    "\n",
    "from PerceiveImport.classes import (\n",
    "    main_class, modality_class, metadata_class,\n",
    "    session_class, condition_class, task_class,\n",
    "    contact_class, run_class\n",
    ")\n",
    "import PerceiveImport.methods.load_rawfile as load_rawfile\n",
    "import PerceiveImport.methods.find_folders as find_folders\n",
    "import PerceiveImport.methods.metadata_helpers as metaHelpers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'PerceiveImport.methods.metadata_helpers' from 'c:\\\\Users\\\\jebe12\\\\Research\\\\PyPerceive_Project\\\\Code\\\\PyPerceive\\\\code\\\\PerceiveImport\\\\methods\\\\metadata_helpers.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload classes during debugging\n",
    "importlib.reload(main_class)\n",
    "importlib.reload(session_class)\n",
    "importlib.reload(task_class)\n",
    "importlib.reload(condition_class)\n",
    "importlib.reload(contact_class)\n",
    "importlib.reload(metadata_class)\n",
    "importlib.reload(modality_class)\n",
    "importlib.reload(load_rawfile)\n",
    "importlib.reload(find_folders)\n",
    "importlib.reload(run_class)\n",
    "importlib.reload(metaHelpers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Change the working directory back to your own Repo after importing PyPerceive\n",
    "    - whenenver you want to change or debug PyPerceive, please change back to the PyPerceive directory and reload the classes\n",
    "    - if you do not wish to change anything in PyPerceive, you can stay in your own Repo directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################     USE THIS DIRECTORY FOR WORKING WITH FOLDERS INSIDE OF YOUR OWN REPO  #######################\n",
    "\n",
    "# get the common path from where you can redirect to your own Repo \n",
    "currentPath = os.getcwd()\n",
    "while currentPath[-5:] != 'Users':\n",
    "    currentPath = os.path.dirname(currentPath)\n",
    "\n",
    "# directory to your repository folder\n",
    "ownRpository_path = os.path.join(currentPath, \"Project\", \"myRepository\", \"code\")\n",
    "sys.path.append(ownRpository_path)\n",
    "\n",
    "# # change directory to code path of your Repo\n",
    "os.chdir(ownRpository_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load example data using PyPerceive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will load all selected perceived MATLAB files by using mne.io.read_raw_fieldtrip()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t### WARNING: NaNs in Metadata Table sub-024 ###\n",
      "NaNs in: sub024_ses-2021061806255999_run-BrainSense20210618063700.mat\n",
      "NaNs in: sub024_ses-2021061806255999_run-BrainSense20210618064000.mat\n",
      "NaNs in: sub024_ses-2021061806255999_run-BrainSense20210618064200.mat\n",
      "NaNs in: sub024_ses-2021061808253999_run-BrainSense20210618084000.mat\n",
      "NaNs in: sub024_ses-2021061808253999_run-BrainSense20210618084300.mat\n",
      "NaNs in: sub024_ses-2021061808253999_run-BrainSense20210618084700.mat\n",
      "NaNs in: sub024_ses-2021092106385396_run-BrainSense20210921070500.mat\n",
      "NaNs in: sub024_ses-2021092106385396_run-BrainSense20210921072300.mat\n",
      "NaNs in: sub024_ses-2021092106385396_run-CHRONIC20210917114914.mat\n",
      "NaNs in: sub024_ses-2021092107452096_run-BrainSense20210921074800.mat\n",
      "NaNs in: sub024_ses-2021092107452096_run-BrainSense20210921080600.mat\n",
      "NaNs in: sub024_ses-2021092107452096_run-BrainSense20210921082400.mat\n",
      "NaNs in: sub024_ses-2021092107452096_run-CHRONIC20210918121914.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610105800.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610111500.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610111700.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610112200.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610112500.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610112700.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610113100.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610114400.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610115200.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610115500.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610115900.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610120100.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610120200.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-BrainSense20220610120500.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022061010445782_run-CHRONIC20210918012914.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022072210000082_run-BrainSense20220609070200.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022072210000082_run-BrainSense20220609071800.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022072210000082_run-BrainSense20220609072200.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022072210000082_run-BrainSense20220609072900.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022072210000082_run-BrainSense20220609073100.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022072210000082_run-BrainSense20220609073500.mat\n",
      "NaNs in: sub-20210615PStn_ses-2022072210000082_run-CHRONIC20210918125914.mat\n",
      "NaNs in: sub-20210615PStn_ses-1948072210000072_run-CHRONIC20210918022914.mat\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=5288\n",
      "    Range : 0 ... 5287 =      0.000 ...    21.148 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=5313\n",
      "    Range : 0 ... 5312 =      0.000 ...    21.248 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=5288\n",
      "    Range : 0 ... 5287 =      0.000 ...    21.148 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=5288\n",
      "    Range : 0 ... 5287 =      0.000 ...    21.148 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=5188\n",
      "    Range : 0 ... 5187 =      0.000 ...    20.748 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=5288\n",
      "    Range : 0 ... 5287 =      0.000 ...    21.148 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=5288\n",
      "    Range : 0 ... 5287 =      0.000 ...    21.148 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=5188\n",
      "    Range : 0 ... 5187 =      0.000 ...    20.748 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=5288\n",
      "    Range : 0 ... 5287 =      0.000 ...    21.148 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=5288\n",
      "    Range : 0 ... 5287 =      0.000 ...    21.148 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=3, n_times=5312\n",
      "    Range : 0 ... 5311 =      0.000 ...    21.244 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=5288\n",
      "    Range : 0 ... 5287 =      0.000 ...    21.148 secs\n",
      "Ready.\n",
      "inserted session (postop, streaming) can not be found in the metadata table\n",
      "inserted session (fu3m, streaming) can not be found in the metadata table\n",
      "inserted session (fu12m, streaming) can not be found in the metadata table\n",
      "Creating RawArray with float64 data, n_channels=6, n_times=30187\n",
      "    Range : 0 ... 30186 =      0.000 ...   120.744 secs\n",
      "Ready.\n",
      "inserted session (postop, indefiniteStreaming) can not be found in the metadata table\n",
      "inserted session (fu3m, indefiniteStreaming) can not be found in the metadata table\n",
      "inserted session (fu12m, indefiniteStreaming) can not be found in the metadata table\n",
      "Creating RawArray with float64 data, n_channels=12, n_times=6500\n",
      "    Range : 0 ... 6499 =      0.000 ...    25.996 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=12, n_times=34687\n",
      "    Range : 0 ... 34686 =      0.000 ...   138.744 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=12, n_times=46500\n",
      "    Range : 0 ... 46499 =      0.000 ...   185.996 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# define an example instance and fill in the values of the dataclass PerceiveData \n",
    "# choose the values you are interested in analyzing further\n",
    "\n",
    "sub_example = main_class.PerceiveData(\n",
    "    sub = \"024\", \n",
    "    incl_modalities=['survey', 'streaming', 'indefiniteStreaming'],\n",
    "    incl_session = [\"postop\", \"fu3m\", \"fu12m\", \"fu18m\"],\n",
    "    incl_condition =['m0s0'],\n",
    "    incl_task = [\"rest\"],\n",
    "    incl_contact = [\"RingL\", \"SegmInterR\", \"SegmIntraR\"],\n",
    "    import_json=False, # for addtionally loading the corresponding JSON files as source files, set to True\n",
    "    warn_for_metaNaNs=True, # True will give you a warning with rows from the metadata table with NaNs. Make sure you have filled out all columns of the file you want to load.\n",
    "    # use_bids=True,  # TODO: add to functionality\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Call examplary data from the instance you loaded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BrainSense Survey - select from each classes in the correct order:\n",
    "    - modality\n",
    "    - session\n",
    "    - condition\n",
    "    - task\n",
    "    - contact\n",
    "    - run\n",
    "    - .data will return the perceived .mat file loaded with mne.io.read_raw_fieldtrip() \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contact Class: BS Surveys are recorded in 3 seperate passes:\n",
    "    - from Ring contacts (01,02,03,12,13,23)\n",
    "    - from Segmented contacts within one directional level (1A1B,1A1C,1B1C,2A2B,2A2C,2B2C)\n",
    "    - from Segmented contacts between two directional levels (1A2A, 1B2B, 1C2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>0 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>6 misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:00:22 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawArray | 6 x 5288 (21.1 s), ~259 kB, data loaded>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BS Survey modality is the only modality with a contact class\n",
    "\n",
    "sub_example.survey.fu12m.m0s0.rest.RingL.run1.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BrainSense Streaming or Indefinite Streaming - select from each classes in the correct order:\n",
    "    - modality\n",
    "    - session\n",
    "    - condition\n",
    "    - task\n",
    "    - run\n",
    "    - .data will return the perceived .mat file loaded with mne.io.read_raw_fieldtrip() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>0 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>4 misc, 2 Stimulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:02:01 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawArray | 6 x 30187 (120.7 s), ~1.4 MB, data loaded>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BS Survey modality is the only modality with a contact class\n",
    "\n",
    "sub_example.streaming.fu18m.m0s0.rest.run1.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MNE Playground"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BS Survey data as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data object has:\n",
      "\t5288 time samples,\n",
      "\tand a sample frequency of 250.0 Hz\n",
      "\twith a recording duration of 21.152 seconds.\n",
      "\t6 channels were labeled as \n",
      "['LFP_L_03_STN_MT', 'LFP_L_13_STN_MT', 'LFP_L_02_STN_MT', 'LFP_L_12_STN_MT', 'LFP_L_01_STN_MT', 'LFP_L_23_STN_MT'].\n"
     ]
    }
   ],
   "source": [
    "data = sub_example.survey.fu18m.m0s0.rest.RingL.run1.data\n",
    "\n",
    "\n",
    "ch_names = data.ch_names\n",
    "n_chan = len(ch_names)\n",
    "n_time_samps = data.n_times #nsamples\n",
    "time_secs = data.times #timepoints set to zero\n",
    "ch_trials = data._data\n",
    "sampling_freq = data.info['sfreq']\n",
    "time_duration = (n_time_samps/sampling_freq).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "print(\n",
    "      f'The data object has:\\n\\t{n_time_samps} time samples,'\n",
    "      f'\\n\\tand a sample frequency of {sampling_freq} Hz' \n",
    "      f'\\n\\twith a recording duration of {time_duration} seconds.' \n",
    "      f'\\n\\t{n_chan} channels were labeled as \\n{ch_names}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyPerceive_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f70f96619c4c5eb645d0e9073112ce77298f8a2779fc08300cec5240d192365"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
