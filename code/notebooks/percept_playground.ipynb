{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyPerceive to select and load Percept recordings "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0a. Loading default packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python and external packages\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "from dataclasses import dataclass, field, fields\n",
    "from itertools import compress\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl import Workbook, load_workbook\n",
    "import xlrd\n",
    "\n",
    "#mne\n",
    "import mne_bids\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet \n",
    "\n",
    "from importlib import reload          \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check package versions\n",
    "\n",
    "developed with:\n",
    "- Python sys 3.10.8\n",
    "- pandas 1.5.1\n",
    "- numpy 1.23.4\n",
    "- mne_bids 0.11.1\n",
    "- mne 1.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some package versions for documentation and reproducability\n",
    "print('Python sys', sys.version)\n",
    "print('pandas', pd.__version__)\n",
    "print('numpy', np.__version__)\n",
    "# print('mne_bids', mne_bids.__version__)\n",
    "print('mne', mne.__version__)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0b. Loading pyPerceive functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_set_code_folder_in_notebook():\n",
    "    \"\"\"\n",
    "    while working in the local pyPerceive repo,\n",
    "    find and set path to the PyPerceive code folder\n",
    "\n",
    "    use function in notebook first, to locate the local\n",
    "    repo and enable import of pyPerceive functions\n",
    "    \"\"\"\n",
    "    project_path = os.getcwd()\n",
    "\n",
    "    while project_path[-10:] != 'PyPerceive':\n",
    "        project_path = os.path.dirname(project_path)\n",
    "\n",
    "    code_path = os.path.join(project_path, 'code')\n",
    "    sys.path.append(code_path)\n",
    "\n",
    "    # change directory to code path\n",
    "    os.chdir(code_path)\n",
    "    \n",
    "    return print(f'working dir set to: {code_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAIN FUNCTION FOR DATA IMPORT\n",
    "\n",
    "# change working directory to ensure correct loading of own functions\n",
    "add_and_set_code_folder_in_notebook()\n",
    "\n",
    "# import main class to work with\n",
    "from PerceiveImport.classes import main_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT ALL SUB CLASSES AND FUNCTIONS FOR DEBUGGING\n",
    "from PerceiveImport.classes import (\n",
    "    main_class, modality_class, metadata_class,\n",
    "    session_class, condition_class, task_class,\n",
    "    contact_class, run_class, chronic_class\n",
    ")\n",
    "import PerceiveImport.methods.load_rawfile as load_rawfile\n",
    "import PerceiveImport.methods.find_folders as find_folders\n",
    "import PerceiveImport.methods.metadata_helpers as metaHelpers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON Anonymize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PerceiveImport.methods.find_folders as find_folders \n",
    "import utils.anonymise_jsons as anonymise_jsons\n",
    "import PerceiveImport.methods.metadata_helpers as metadata_helpers \n",
    "\n",
    "importlib.reload(anonymise_jsons)\n",
    "importlib.reload(find_folders)\n",
    "importlib.reload(metadata_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anonymise_jsons.anonymise_jsons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_helpers.get_terminology(\n",
    "    key = \"session\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test Data Loading for Streaming and Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an example instance and fill in the values of the dataclass PerceiveData \n",
    "# choose the values you are interested in analyzing further\n",
    "\n",
    "importlib.reload(run_class)\n",
    "importlib.reload(load_rawfile)\n",
    "\n",
    "# sub030 = main_class.PerceiveData(\n",
    "#     sub = \"030\", \n",
    "#     incl_modalities=['streaming', ],  # 'survey', 'indefiniteStreaming'\n",
    "#     incl_session = [\"fu12m\"],\n",
    "#     incl_condition =['m1s0', 'm1s1',],\n",
    "#     incl_task = [\"rest\", \"ChangingPositionMoveArt\"],\n",
    "#     incl_contact = [\"RingL\", \"RingR\"],\n",
    "#     import_json=False,\n",
    "#     warn_for_metaNaNs=True,\n",
    "#     allow_NaNs_in_metadata=True,\n",
    "#     # use_bids=True,  # TODO: add to functionality\n",
    "# )\n",
    "\n",
    "dat = main_class.PerceiveData(\n",
    "    sub = \"040\", \n",
    "    incl_modalities=['streaming', 'survey'],  # 'survey', 'indefiniteStreaming'\n",
    "    incl_session = [\"fu12m\"],\n",
    "    incl_condition =['m0s0', 'm1s0', 'm1s1',],\n",
    "    incl_task = [\"rest\", ],  # \"ChangingPositionMoveArt\"\n",
    "    # incl_contact = [\"RingL\", \"RingR\"],\n",
    "    import_json=False,\n",
    "    warn_for_metaNaNs=True,\n",
    "    allow_NaNs_in_metadata=True,\n",
    "    # use_bids=True,  # TODO: add to functionality\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.streaming.fu12m.m1s1.rest.run1.data.ch_names\n",
    "\n",
    "dat.survey.fu12m.m1s0.rest.SegmIntraL.run1.data.ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_sub030.streaming.fu12m.m1s1.rest.run1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHEN IMPORT FROM .MAT (import_json=False)\n",
    "sub030.streaming.fu12m.m1s0.rest.run1.data  # MNE RawArray, \n",
    "\n",
    "\n",
    "sub030.streaming.fu12m.m1s0.rest.run1.data.get_data().shape\n",
    "\n",
    "print(sub030.streaming.fu12m.m1s0.rest.run1.data.ch_names)\n",
    "\n",
    "plt.plot(sub030.streaming.fu12m.m1s0.rest.run1.data.get_data()[0, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secs = sub030.streaming.fu12m.m1s0.rest.run1.data.times.copy()\n",
    "type(secs)\n",
    "start_time = 85  # seconds from start\n",
    "end_time = 92\n",
    "\n",
    "index_start = np.where(secs == start_time)[0][0]\n",
    "index_end = np.where(secs == end_time)[0][0]\n",
    "\n",
    "print(index_start, index_end)\n",
    "\n",
    "mov_part = sub030.streaming.fu12m.m1s0.rest.run1.data.get_data()[0, index_start:index_end]\n",
    "\n",
    "type(mov_part)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Data Loading for Chronic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case of debugging\n",
    "from PerceiveImport.methods import extract_chronic_timeline_samples as extract_chronic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an example instance and fill in the values of the dataclass PerceiveData \n",
    "# choose the values you are interested in analyzing further\n",
    "importlib.reload(find_folders)\n",
    "importlib.reload(extract_chronic)\n",
    "importlib.reload(chronic_class)\n",
    "importlib.reload(metaHelpers)\n",
    "importlib.reload(main_class)\n",
    "importlib.reload(modality_class)\n",
    "\n",
    "dat = main_class.PerceiveData(\n",
    "    sub = \"080\", \n",
    "    incl_modalities=['chronic'],\n",
    "    import_json=True,\n",
    "    warn_for_metaNaNs=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dat.chronic.events))\n",
    "\n",
    "sum([e.contains_LFP for e in dat.chronic.events])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first take all unique events with LFP data\n",
    "uniq_lfp_times, uniq_lfp_idx = np.unique([e.time for e in dat.chronic.events\n",
    "                                  if e.contains_LFP],  #\n",
    "                                 return_index=True)\n",
    "uniq_lfp_events = list(np.array(dat.chronic.events)[uniq_lfp_idx])\n",
    "\n",
    "uniq_noLFP_times, uniq_noLFP_idx = np.unique([e.time for e in dat.chronic.events\n",
    "                                              if not e.contains_LFP],  #\n",
    "                                             return_index=True)\n",
    "uniq_nolfp_events = list(np.array(dat.chronic.events)[uniq_noLFP_idx])\n",
    "\n",
    "uniq_nolfp_events = [e for e in uniq_nolfp_events\n",
    "                     if e.time not in uniq_lfp_times]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Direct access JSONs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- finish SnapSHot extraction\n",
    "- fix JSON import, extract recording order from excel and get metadata\n",
    "    - use this to order the list of JSON data\n",
    "    - then use correct and check missings on each data part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test brainsense with different files\n",
    "\n",
    "# test snapshots and chronic\n",
    "json_fname = 'Report_Json_Session_Report_20231123T141534.json'\n",
    "j = load_rawfile.load_sourceJSON('047', json_fname)\n",
    "\n",
    "json_fname = 'Report_Json_Session_Report_20231123T141637.json'\n",
    "j2 = load_rawfile.load_sourceJSON('047', json_fname)\n",
    "\n",
    "json_fname = 'Report_Json_Session_Report_20231123T141705.json'\n",
    "j3 = load_rawfile.load_sourceJSON('047', json_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j.keys())\n",
    "print(j2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_data_codes = {\n",
    "    'signal_test': 'CalibrationTests',\n",
    "    'streaming': 'BrainSenseTimeDomain',\n",
    "    'survey': 'LfpMontageTimeDomain',\n",
    "    'indef_streaming': 'IndefiniteStreaming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PerceiveImport.methods.timezone_handling as tz_handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(tz_handling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j[prc_data_codes['survey']]  # TO INTEGRATE\n",
    "\n",
    "# check_and_correct_missings_in_lfp(j['BrainSenseLfp'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = 'streaming'\n",
    "\n",
    "list_of_streamings = j[prc_data_codes[mod]]\n",
    "n_streamings = len(list_of_streamings)\n",
    "\n",
    "\n",
    "list_of_streamings2 = j2[prc_data_codes[mod]]\n",
    "\n",
    "# n_exp_streamings = extract from metadata\n",
    "# check whether n-streamings match metdata table \n",
    "# if n_streamings == n_streamings: ...\n",
    "\n",
    "for dat in list_of_streamings2:\n",
    "    print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_streamings[0]['GlobalPacketSizes']\n",
    "\n",
    "print(list_of_streamings[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = list_of_streamings[0]\n",
    "for i_dat, dat in enumerate(list_of_streamings):\n",
    "    print(i_dat)\n",
    "    new_lfp = load_rawfile.check_and_correct_missings_in_lfp(dat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyPerceive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89cb9b15ea7fbcc6bc9b1c7e86ec8f92184be73d513127a97a923adf23b86793"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
